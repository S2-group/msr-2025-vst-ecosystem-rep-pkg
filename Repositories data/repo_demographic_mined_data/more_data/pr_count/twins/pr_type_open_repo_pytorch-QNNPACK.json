{"total_count": 2, "incomplete_results": false, "items": [{"url": "https://api.github.com/repos/pytorch/QNNPACK/issues/54", "repository_url": "https://api.github.com/repos/pytorch/QNNPACK", "labels_url": "https://api.github.com/repos/pytorch/QNNPACK/issues/54/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/QNNPACK/issues/54/comments", "events_url": "https://api.github.com/repos/pytorch/QNNPACK/issues/54/events", "html_url": "https://github.com/pytorch/QNNPACK/pull/54", "id": 423904047, "node_id": "MDExOlB1bGxSZXF1ZXN0MjYzMzc0MTIw", "number": 54, "title": "Q8GEMM per-channel quant 32bit/16bit accumulation", "user": {"login": "mortzur", "id": 18488742, "node_id": "MDQ6VXNlcjE4NDg4NzQy", "avatar_url": "https://avatars.githubusercontent.com/u/18488742?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mortzur", "html_url": "https://github.com/mortzur", "followers_url": "https://api.github.com/users/mortzur/followers", "following_url": "https://api.github.com/users/mortzur/following{/other_user}", "gists_url": "https://api.github.com/users/mortzur/gists{/gist_id}", "starred_url": "https://api.github.com/users/mortzur/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mortzur/subscriptions", "organizations_url": "https://api.github.com/users/mortzur/orgs", "repos_url": "https://api.github.com/users/mortzur/repos", "events_url": "https://api.github.com/users/mortzur/events{/privacy}", "received_events_url": "https://api.github.com/users/mortzur/received_events", "type": "User", "user_view_type": "public", "site_admin": false}, "labels": [], "state": "open", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-03-21T19:28:51Z", "updated_at": "2019-06-10T23:50:40Z", "closed_at": null, "author_association": "NONE", "sub_issues_summary": {"total": 0, "completed": 0, "percent_completed": 0}, "active_lock_reason": null, "draft": false, "pull_request": {"url": "https://api.github.com/repos/pytorch/QNNPACK/pulls/54", "html_url": "https://github.com/pytorch/QNNPACK/pull/54", "diff_url": "https://github.com/pytorch/QNNPACK/pull/54.diff", "patch_url": "https://github.com/pytorch/QNNPACK/pull/54.patch", "merged_at": null}, "body": "Micro-kernels implementation of the following:\r\n\r\n* Q8GEMM with per-channel weights quantization parameters (.c) + unit tests + benchmarks\r\n\r\n* Q8GEMM with per-channel weights quantization parameters for AARCH32 (.S) + unit tests + benchmarks\r\n\r\n* Q8GEMM with per-channel weights quantization parameters with 16bit opportunistic accumulation (.c) + unit tests + benchmarks\r\n\r\n* Q8GEMM with per-channel weights quantization parameters with 16bit opportunistic accumulation for AARCH32 (.S) + unit tests + benchmarks", "reactions": {"url": "https://api.github.com/repos/pytorch/QNNPACK/issues/54/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/pytorch/QNNPACK/issues/54/timeline", "performed_via_github_app": null, "state_reason": null, "score": 1.0}]}